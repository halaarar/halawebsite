## Bank Marketing predictions 
Overview
The Bank Marketing Prediction Project applies machine learning techniques to enhance bank marketing strategies by predicting whether a customer will subscribe to a term deposit based on demographic and campaign-related data.

The goal was to develop a predictive model that helps banks optimize resource allocation, minimize marketing costs, and improve customer conversion rates. This project incorporated end-to-end data science workflows, data preprocessing, and model evaluation to identify the most effective approach for targeted marketing.

💡 Key Contributions & Impact
✔ Developed predictive models to classify customer responses to bank marketing campaigns.
✔ Built a fully reproducible machine learning pipeline using Python and Jupyter Notebooks.
✔ Implemented Docker for containerized deployment, ensuring portability across environments.
✔ Used GitHub Actions for CI/CD, automating testing and workflow execution.
✔ Applied statistical analysis and feature engineering to optimize model performance.
✔ Conducted error analysis and class imbalance handling to enhance predictions.
✔ Created a structured reporting system, generating a detailed analysis of the models’ effectiveness.

Project Objectives
🔹 Predict Customer Subscription Behavior: Determine whether a customer will subscribe to a term deposit based on demographic and campaign-related data.
🔹 Optimize Marketing Strategies: Identify patterns in customer responses to improve targeting and reduce costs.
🔹 Automate Data Processing & Model Training: Develop a scalable pipeline using Click, Docker, and Makefiles.
🔹 Enhance Model Interpretability: Implement feature importance analysis to guide data-driven decision-making.

Technical Implementation
1️⃣ Data Preprocessing & Feature Engineering
Processing raw customer data involved several key steps:
✔ Handled missing values and inconsistencies using pandas and NumPy.
✔ Applied feature scaling and normalization for numerical attributes.
✔ Used one-hot encoding to convert categorical variables into a machine-readable format.
✔ Class balancing techniques (oversampling, undersampling) to address the imbalance between subscribers and non-subscribers.

Example Code for Data Cleaning & Feature Engineering:

python
Copy
Edit
from sklearn.preprocessing import StandardScaler, OneHotEncoder
import pandas as pd

# Load dataset
df = pd.read_csv("data/bank-additional-full.csv")

# Feature scaling
scaler = StandardScaler()
df[["age", "campaign", "previous"]] = scaler.fit_transform(df[["age", "campaign", "previous"]])

# One-hot encoding categorical features
encoder = OneHotEncoder()
encoded_features = encoder.fit_transform(df[["job", "marital", "education"]]).toarray()
2️⃣ Machine Learning Models & Performance Evaluation
Implemented two machine learning models:

📌 Logistic Regression

Focused on interpretability and explainability.
Prioritized minimizing false positives, achieving high precision (0.70).
Used L1 regularization to prevent overfitting.
📌 Decision Tree Classifier

More flexible in handling non-linear relationships.
Achieved higher recall (0.23) but increased false positives.
Required pruning and hyperparameter tuning for optimal performance.
✔ Performance Metrics Used:

Accuracy: Measures overall correctness.
Precision: Reduces false positives (important for targeted marketing).
Recall: Identifies more actual subscribers.
F1 Score: Balances precision and recall.
Model Performance Results:

Model	Accuracy	Precision	Recall	F1 Score
Logistic Regression	88.5%	0.70	0.20	0.31
Decision Tree	89.7%	0.64	0.23	0.34
💡 Findings:

Logistic Regression was best for reducing false positives.
Decision Tree performed better in identifying actual subscribers.
Further model tuning needed to balance precision and recall.
3️⃣ CI/CD & Automation with Docker & GitHub Actions
To ensure reproducibility and scalability, I implemented CI/CD pipelines using Docker & GitHub Actions.

✔ Dockerized the project for easy deployment.
✔ Automated testing using Pytest to validate model outputs.
✔ GitHub Actions triggered CI/CD workflows, ensuring seamless execution.

Example of Dockerized Workflow:

yaml
Copy
Edit
name: CI/CD Pipeline

on:
  push:
    branches:
      - main

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v2
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: "3.10"
      - name: Install dependencies
        run: pip install -r requirements.txt
      - name: Run tests
        run: pytest --cov=src
🚀 Impact: CI/CD automation reduced manual intervention, ensuring code integrity and rapid deployment.

4️⃣ Running the Analysis
💡 Option 1: Run Using Docker
1️⃣ Install Docker.
2️⃣ Clone the repository.

bash
Copy
Edit
git clone https://github.com/mindy001/BankMarketingPreditions-.git
cd BankMarketingPreditions-
3️⃣ Start the container.

bash
Copy
Edit
docker-compose up
4️⃣ Access JupyterLab for interactive analysis.

💡 Option 2: Run Using Makefile
1️⃣ Clone repository and activate environment.

bash
Copy
Edit
git clone https://github.com/mindy001/BankMarketingPreditions-.git
cd BankMarketingPreditions-
conda env create -f env/environment.yml  
conda activate bankenv
2️⃣ Generate analysis report.

bash
Copy
Edit
make all
3️⃣ Open the generated PDF report.

Key Takeaways & Impact
🚀 Through this project, I gained experience in:
✔ Building scalable ML models – Data preprocessing, feature engineering, model selection.
✔ Data Engineering & Pipelines – Automated workflows using Makefile and Docker.
✔ Machine Learning for Marketing – Class imbalance handling, precision-recall tradeoffs.
✔ CI/CD & Automation – GitHub Actions for testing, deployment, and reproducibility.
✔ Version Control & Collaboration – GitHub repository management, pull requests, team contributions.

🔹 Future Enhancements:
✅ Hyperparameter tuning using GridSearchCV for improved accuracy.
✅ Feature selection analysis to reduce redundant variables.
✅ Deploying an API to allow real-time model inference for banks.

Final Thoughts
This project strengthened my ability to develop end-to-end machine learning solutions for real-world business challenges. By combining ML modeling, automation, and CI/CD, I created a fully scalable, deployable, and interpretable system.

🔗 Check out the full report: Final Report
🔗 GitHub Repository: Bank Marketing Prediction

Would love to connect with others interested in marketing analytics, data-driven decision-making, and AI-powered business solutions! 🚀


## Credit Card Default Prediction Project
links that takes you to the project section of this
link that takes you to the github page

•	Analyzed and preprocessed the Default of Credit Card Clients dataset to predict credit card payment defaults.
•	Implemented decision tree models and hyperparameter tuning to optimize model performance. 
•	GitHub Repository: https://github.ubc.ca/mds-2024-25/DSCI_573_Lab4_hala_fazeeia/tree/main


