# My Projects
Welcome to a summary of some of my most exciting projects! Each one represents a unique application of data science, machine learning, and analytics to solve real-world problems. Click on the links to explore the full project details and GitHub repositories.


## Health Science Calculator

Health Science Calculator is a Python package designed to provide accurate and efficient health metric calculations. It supports Total Daily Energy Expenditure (TDEE), Basal Metabolic Rate (BMR), and Body Mass Index (BMI) computations, making it useful for health professionals, researchers, and fitness enthusiasts.

This project was developed as part of a collaborative effort using best practices in software engineering, automation, and version control to ensure code quality, maintainability, and scalability.

### Project Goals & Contributions
âœ” Developed a modular Python package for health-related calculations using object-oriented programming (OOP) principles.
âœ” Implemented core functions to compute BMI, BMR, TDEE, and perform unit conversions to standardize health data.
âœ” Integrated Pytest for automated testing, ensuring the accuracy of implemented functions and maintaining 100% test coverage.
âœ” Leveraged GitHub Actions for CI/CD, automating testing, deployment, and ensuring seamless version control.
âœ” Published the package to PyPI, making it accessible for installation and use via pip install healthsciencecalculator.
âœ” Collaborated with a team, applying version control workflows (branching, merging, pull requests) to streamline development.
âœ” Designed an API reference and technical documentation using Sphinx and Read the Docs, ensuring clarity for users.

Technical Implementation
1ï¸âƒ£ Core Functionality
The package provides key health-related calculations:

ğŸ“Œ get_tdee() â€“ Calculates Total Daily Energy Expenditure (TDEE) based on BMR and activity level.
ğŸ“Œ get_bmi() â€“ Computes Body Mass Index (BMI) and classifies users into categories (underweight, normal, overweight, obese).
ğŸ“Œ get_bmr() â€“ Uses the Harris-Benedict equation to compute Basal Metabolic Rate (BMR) based on weight, height, age, and sex.
ğŸ“Œ unit_convert() â€“ Converts between metric and imperial units for weight, height, temperature, and volume.

ğŸ’¡ Each function is rigorously tested and optimized to provide high-accuracy calculations.

2ï¸âƒ£ Continuous Integration & Deployment (CI/CD)
To ensure code stability and reliability, I implemented GitHub Actions for CI/CD, enabling:

âœ” Automated testing via Pytest after every code commit or pull request.
âœ” Linting and style checks using Pylint to maintain code consistency.
âœ” Test coverage reporting using pytest-cov and Codecov for tracking improvements.
âœ” Automated package deployment to PyPI using GitHub Actions, ensuring seamless updates.

ğŸ”¹ CI/CD Workflow Overview:

Push or Pull Request: Triggers automated tests on GitHub Actions.
Run Pytest: Tests all functions for expected outputs, error handling, and edge cases.
Deploy to PyPI: If all tests pass, the package is automatically updated on PyPI.
ğŸ’¡ Impact: CI/CD ensures code quality, early bug detection, and smooth integration into production.

3ï¸âƒ£ Automated Testing with Pytest
Testing is crucial in health applications, so I implemented comprehensive unit tests using Pytest:

âœ” Validated all health metric calculations against known industry standards.
âœ” Implemented edge-case handling (e.g., division by zero, incorrect input types).
âœ” Ran parameterized tests to ensure correctness across various inputs.
âœ” Tracked test coverage using pytest-cov, achieving 100% test coverage.

ğŸ’¡ Testing Commands:

bash
Copy
Edit
# Run all tests
pytest  

# Run tests with coverage report
pytest --cov=healthsciencecalculator
4ï¸âƒ£ Collaboration & Version Control
Working on this project in a team required effective version control:

âœ” Used GitHub for repository management, implementing branching strategies and pull requests.
âœ” Code reviews were conducted for all new features, ensuring high-quality contributions.
âœ” Maintained a changelog to document package updates and feature improvements.

Installation & Usage
ğŸ“Œ Install the package via pip:

bash
Copy
Edit
pip install healthsciencecalculator
ğŸ“Œ Example Usage:

python
Copy
Edit
from healthsciencecalculator import get_bmi, get_tdee

# Calculate BMI
bmi_result = get_bmi(weight=70, height=1.75)
print(f"BMI: {bmi_result.bmi:.2f}, Category: {bmi_result.category}")

# Calculate TDEE
tdee = get_tdee(bmr=1500, activity_level="moderately active")
print(f"TDEE: {tdee:.2f} kcal/day")
Key Takeaways & Impact
ğŸš€ Developing a robust Python package strengthened my skills in:
âœ” Software Development â€“ Object-oriented programming, modular design, API development.
âœ” Machine Learning & Analytics â€“ Data validation, unit conversions, structured data processing.
âœ” Automation & CI/CD â€“ GitHub Actions, Pytest, automated package deployment.
âœ” Team Collaboration â€“ Git workflows, issue tracking, and effective code documentation.
âœ” Technical Communication â€“ Writing clear documentation and API references for user accessibility.

This project enhanced my ability to develop scalable, well-tested software solutions, a skill directly applicable to data engineering, AI, and healthcare analytics roles.




## Bank Marketing predictions 
Overview
The Bank Marketing Prediction Project applies machine learning techniques to enhance bank marketing strategies by predicting whether a customer will subscribe to a term deposit based on demographic and campaign-related data.

The goal was to develop a predictive model that helps banks optimize resource allocation, minimize marketing costs, and improve customer conversion rates. This project incorporated end-to-end data science workflows, data preprocessing, and model evaluation to identify the most effective approach for targeted marketing.

ğŸ’¡ Key Contributions & Impact
âœ” Developed predictive models to classify customer responses to bank marketing campaigns.
âœ” Built a fully reproducible machine learning pipeline using Python and Jupyter Notebooks.
âœ” Implemented Docker for containerized deployment, ensuring portability across environments.
âœ” Used GitHub Actions for CI/CD, automating testing and workflow execution.
âœ” Applied statistical analysis and feature engineering to optimize model performance.
âœ” Conducted error analysis and class imbalance handling to enhance predictions.
âœ” Created a structured reporting system, generating a detailed analysis of the modelsâ€™ effectiveness.

Project Objectives
ğŸ”¹ Predict Customer Subscription Behavior: Determine whether a customer will subscribe to a term deposit based on demographic and campaign-related data.
ğŸ”¹ Optimize Marketing Strategies: Identify patterns in customer responses to improve targeting and reduce costs.
ğŸ”¹ Automate Data Processing & Model Training: Develop a scalable pipeline using Click, Docker, and Makefiles.
ğŸ”¹ Enhance Model Interpretability: Implement feature importance analysis to guide data-driven decision-making.

Technical Implementation
1ï¸âƒ£ Data Preprocessing & Feature Engineering
Processing raw customer data involved several key steps:
âœ” Handled missing values and inconsistencies using pandas and NumPy.
âœ” Applied feature scaling and normalization for numerical attributes.
âœ” Used one-hot encoding to convert categorical variables into a machine-readable format.
âœ” Class balancing techniques (oversampling, undersampling) to address the imbalance between subscribers and non-subscribers.

Example Code for Data Cleaning & Feature Engineering:

python
Copy
Edit
from sklearn.preprocessing import StandardScaler, OneHotEncoder
import pandas as pd

# Load dataset
df = pd.read_csv("data/bank-additional-full.csv")

# Feature scaling
scaler = StandardScaler()
df[["age", "campaign", "previous"]] = scaler.fit_transform(df[["age", "campaign", "previous"]])

# One-hot encoding categorical features
encoder = OneHotEncoder()
encoded_features = encoder.fit_transform(df[["job", "marital", "education"]]).toarray()
2ï¸âƒ£ Machine Learning Models & Performance Evaluation
Implemented two machine learning models:

ğŸ“Œ Logistic Regression

Focused on interpretability and explainability.
Prioritized minimizing false positives, achieving high precision (0.70).
Used L1 regularization to prevent overfitting.
ğŸ“Œ Decision Tree Classifier

More flexible in handling non-linear relationships.
Achieved higher recall (0.23) but increased false positives.
Required pruning and hyperparameter tuning for optimal performance.
âœ” Performance Metrics Used:

Accuracy: Measures overall correctness.
Precision: Reduces false positives (important for targeted marketing).
Recall: Identifies more actual subscribers.
F1 Score: Balances precision and recall.
Model Performance Results:

Model	Accuracy	Precision	Recall	F1 Score
Logistic Regression	88.5%	0.70	0.20	0.31
Decision Tree	89.7%	0.64	0.23	0.34
ğŸ’¡ Findings:

Logistic Regression was best for reducing false positives.
Decision Tree performed better in identifying actual subscribers.
Further model tuning needed to balance precision and recall.
3ï¸âƒ£ CI/CD & Automation with Docker & GitHub Actions
To ensure reproducibility and scalability, I implemented CI/CD pipelines using Docker & GitHub Actions.

âœ” Dockerized the project for easy deployment.
âœ” Automated testing using Pytest to validate model outputs.
âœ” GitHub Actions triggered CI/CD workflows, ensuring seamless execution.

Example of Dockerized Workflow:

yaml
Copy
Edit
name: CI/CD Pipeline

on:
  push:
    branches:
      - main

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v2
      - name: Set up Python
        uses: actions/setup-python@v2
        with:
          python-version: "3.10"
      - name: Install dependencies
        run: pip install -r requirements.txt
      - name: Run tests
        run: pytest --cov=src
ğŸš€ Impact: CI/CD automation reduced manual intervention, ensuring code integrity and rapid deployment.

4ï¸âƒ£ Running the Analysis
ğŸ’¡ Option 1: Run Using Docker
1ï¸âƒ£ Install Docker.
2ï¸âƒ£ Clone the repository.

bash
Copy
Edit
git clone https://github.com/mindy001/BankMarketingPreditions-.git
cd BankMarketingPreditions-
3ï¸âƒ£ Start the container.

bash
Copy
Edit
docker-compose up
4ï¸âƒ£ Access JupyterLab for interactive analysis.

ğŸ’¡ Option 2: Run Using Makefile
1ï¸âƒ£ Clone repository and activate environment.

bash
Copy
Edit
git clone https://github.com/mindy001/BankMarketingPreditions-.git
cd BankMarketingPreditions-
conda env create -f env/environment.yml  
conda activate bankenv
2ï¸âƒ£ Generate analysis report.

bash
Copy
Edit
make all
3ï¸âƒ£ Open the generated PDF report.

Key Takeaways & Impact
ğŸš€ Through this project, I gained experience in:
âœ” Building scalable ML models â€“ Data preprocessing, feature engineering, model selection.
âœ” Data Engineering & Pipelines â€“ Automated workflows using Makefile and Docker.
âœ” Machine Learning for Marketing â€“ Class imbalance handling, precision-recall tradeoffs.
âœ” CI/CD & Automation â€“ GitHub Actions for testing, deployment, and reproducibility.
âœ” Version Control & Collaboration â€“ GitHub repository management, pull requests, team contributions.

ğŸ”¹ Future Enhancements:
âœ… Hyperparameter tuning using GridSearchCV for improved accuracy.
âœ… Feature selection analysis to reduce redundant variables.
âœ… Deploying an API to allow real-time model inference for banks.

Final Thoughts
This project strengthened my ability to develop end-to-end machine learning solutions for real-world business challenges. By combining ML modeling, automation, and CI/CD, I created a fully scalable, deployable, and interpretable system.

ğŸ”— Check out the full report: Final Report
ğŸ”— GitHub Repository: Bank Marketing Prediction

Would love to connect with others interested in marketing analytics, data-driven decision-making, and AI-powered business solutions! ğŸš€


## Credit Card Default Prediction Project
links that takes you to the project section of this
link that takes you to the github page

â€¢	Analyzed and preprocessed the Default of Credit Card Clients dataset to predict credit card payment defaults.
â€¢	Implemented decision tree models and hyperparameter tuning to optimize model performance. 
â€¢	GitHub Repository: https://github.ubc.ca/mds-2024-25/DSCI_573_Lab4_hala_fazeeia/tree/main




## The Data Science Starter Kit - Blog
Overview
A beginner-friendly blog designed to help aspiring data scientists get started with fundamental concepts and practical tools.

What I Did:
âœ” Authored blog posts covering topics such as Git & version control, data visualization, and statistical analysis.
âœ” Developed tutorials and code examples to guide beginners through key data science workflows.
âœ” Created a promotional video to increase community engagement and drive traffic to the blog.
âœ” Maintained a GitHub repository for code snippets, datasets, and Jupyter notebooks.
âœ” Collaborated with peers to expand content and ensure clarity for diverse audiences.

Technologies & Skills Used:
ğŸ“Œ Python | R | Git & Version Control | Data Visualization | Educational Content Creation | Technical Writing



Ongoing & Future Projects
NYPD Arrest Tracker App (Work in Progress)
A dashboard designed for NYC government executives to track and analyze NYPD arrest metrics using real 2023 arrest data.

âœ” Developing interactive data visualizations (maps, bar charts, time-series charts) using Plotly and Seaborn.
âœ” Designing a user-friendly dashboard with Dash for real-time data exploration.
âœ” Implementing filtering options to dynamically analyze crime trends by borough, precinct, and crime type.